{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from Inn2 import RadynversionNet, AtmosData, RadynversionTrainer\n",
    "import loss as Loss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "from time import time\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLocation1 = '/local0/scratch/HAlphaGridExportStatic/DoublePicoMegaPickle50.pickle'\n",
    "dataLocation1a = '/local0/scratch/HAlphaGridExportStatic/DoublePicoMegaMassPickle50.pickle'\n",
    "# dataLocation3 = '/local0/scratch/HAlphaGridExportStatic/MiniBalancedTraining.pickle'\n",
    "dataLocation2 = '/local0/scratch/HAlphaGridExportStatic/TestPickle50.pickle'\n",
    "# dataLocation = '/local0/scratch/Chris/DoublePicoMegaPickle50.pickle'\n",
    "# dataLocation = 'G:\\\\DoublePicoMegaPickle.pickle'\n",
    "balancedData = 'MiniBalancedTraining.pickle'\n",
    "\n",
    "# data = AtmosData([dataLocation1, dataLocation2], resampleWl=30)\n",
    "data = AtmosData([dataLocation1], resampleWl=30)\n",
    "# data = AtmosData([balancedData], resampleWl=30)\n",
    "data.split_data_and_init_loaders(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Inv0 has following input dimensions:\n",
      "\t Output #0 of node Input (0-pad extra channels): (384,)\n",
      "\n",
      "Node Permute0 has following input dimensions:\n",
      "\t Output #0 of node Inv0: (384,)\n",
      "\n",
      "Node Inv1 has following input dimensions:\n",
      "\t Output #0 of node Permute0: (384,)\n",
      "\n",
      "Node Permute1 has following input dimensions:\n",
      "\t Output #0 of node Inv1: (384,)\n",
      "\n",
      "Node Inv2 has following input dimensions:\n",
      "\t Output #0 of node Permute1: (384,)\n",
      "\n",
      "Node Permute2 has following input dimensions:\n",
      "\t Output #0 of node Inv2: (384,)\n",
      "\n",
      "Node Inv3 has following input dimensions:\n",
      "\t Output #0 of node Permute2: (384,)\n",
      "\n",
      "Node Permute3 has following input dimensions:\n",
      "\t Output #0 of node Inv3: (384,)\n",
      "\n",
      "Node Inv4 has following input dimensions:\n",
      "\t Output #0 of node Permute3: (384,)\n",
      "\n",
      "Node Output has following input dimensions:\n",
      "\t Output #0 of node Inv4: (384,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inRepr = [('ne', data.ne.shape[1]), ('temperature', data.temperature.shape[1]), ('vel', data.vel.shape[1]), ('!!PAD',)]\n",
    "outRepr = [('LatentSpace', int(data.ne.shape[1]*3)), ('!!PAD',), ('Halpha', data.lines[0].shape[1]), ('Ca8542', data.lines[1].shape[1])]\n",
    "model = RadynversionNet(inRepr, outRepr, dropout=0.00, zeroPadding=0, minSize=384, numInvLayers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RadynversionTrainer(model, data, dev)\n",
    "trainer.training_params(2000, lr=1.5e-3, zerosNoiseScale=5e-2, wPred=4000.0, wLatent=900.0, wRev=1000.0,\n",
    "#                         loss_latent=Loss.mmd_multiscale_on(dev, alphas=[3, 4, 6, 9, 16]),\n",
    "                        loss_latent=Loss.mmd_multiscale_on(dev, alphas=[8, 11]),\n",
    "#                         loss_backward=Loss.mmd_multiscale_on(dev, alphas=[4, 5, 6, 12, 30]),\n",
    "                        loss_backward=Loss.mmd_multiscale_on(dev, alphas=[1.4, 2, 5.5, 7]),\n",
    "                        loss_fit=Loss.mse)\n",
    "totalEpochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_checkpoint(filename):\n",
    "        if os.path.isfile(filename):\n",
    "            print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "            checkpoint = torch.load(filename)\n",
    "            totalEpochs = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            trainer.optim.load_state_dict(checkpoint['optimizer'])\n",
    "            trainer.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpt_14112018_2400_12000.pth.tar'\n",
      "=> loaded checkpoint 'checkpt_14112018_2400_12000.pth.tar' (epoch 2346)\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint('checkpt_14112018_2400_12000.pth.tar')\n",
    "# load_checkpoint('checkpt_mass_800.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(data.testLoader))\n",
    "#     xPad = torch.cat((x, torch.zeros(trainer.miniBatchSize, model.totChannels - model.numXChannels, model.channelSize + model.zeroPadding)), dim=1)\n",
    "#     xPadShape = xPad.shape\n",
    "#     xPad = torch.reshape(xPad, (trainer.miniBatchSize, -1))\n",
    "    x = x.to(dev)\n",
    "    pad_fn = lambda *x: torch.zeros(*x, device=dev)\n",
    "    inp = model.inSchema.fill({'ne': x[:, 0] + 0.0 * torch.randn(x[:,0].shape).to(dev),\n",
    "                                'temperature': x[:, 1] + 0.0 * torch.randn(x[:, 1].shape).to(dev),\n",
    "                                'vel': x[:, 2]},\n",
    "                               zero_pad_fn=pad_fn)\n",
    "    yz = model(inp.to(dev))\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].plot(yz[0, model.outSchema.Halpha].cpu().numpy())\n",
    "    ax[0].plot(y[0, 0].numpy())\n",
    "    ax[1].plot(yz[0, model.outSchema.Ca8542].cpu().numpy())\n",
    "    ax[1].plot(y[0, 1].numpy()); fig.show(); fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(data.testLoader))\n",
    "    a = max(1.0 / x.shape[0], 0.002)\n",
    "    y = torch.ones_like(y) * y[0, :, :]\n",
    "    yz = model.outSchema.fill({'Halpha': y[:, 0] + 0.0 * torch.randn(y[:,0].shape), 'Ca8542': y[:, 1] + 0.0 * torch.randn(y[:,1].shape), 'LatentSpace': torch.randn})\n",
    "    xOut = model(yz.to(dev), rev=True)\n",
    "    fig, ax = plt.subplots(3,2)\n",
    "    ax[0, 0].plot(yz[0, model.outSchema.Halpha].cpu().numpy())\n",
    "    ax[0, 1].plot(yz[0, model.outSchema.Ca8542].cpu().numpy())\n",
    "    ax[0, 0].plot(y[0, 0].cpu().numpy(), '--')\n",
    "    ax[0, 1].plot(y[0, 1].cpu().numpy(), '--')\n",
    "    \n",
    "    vSign = xOut[:, model.inSchema.vel] / torch.abs(xOut[:, model.inSchema.vel])\n",
    "    vSign[torch.isnan(vSign)] = 0\n",
    "    vel = vSign * (10**torch.abs(xOut[:, model.inSchema.vel]) - 1.0)\n",
    "    \n",
    "    velInSign = x[0,2] / torch.abs(x[0, 2])\n",
    "    velInSign[torch.isnan(velInSign)] = 0\n",
    "    velIn = velInSign * (10**torch.abs(x[0,2]) - 1.0)\n",
    "    for i in range(x.shape[0]):\n",
    "        ax[1, 0].plot(data.z.numpy(), xOut[i, model.inSchema.ne].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[1, 1].plot(data.z.numpy(), xOut[i, model.inSchema.temperature].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[2, 0].plot(data.z.numpy(), vel[i].cpu().numpy(), c='r', alpha=a)\n",
    "    ax[1, 0].plot(data.z.numpy(), x[0, 0].cpu().numpy(), '--')\n",
    "    ax[1, 1].plot(data.z.numpy(), x[0, 1].cpu().numpy(), '--')\n",
    "    ax[2, 0].plot(data.z.numpy(), velIn.cpu().numpy(), '--')\n",
    "    \n",
    "    ax[0, 0].set_title(r'H$\\alpha$')\n",
    "    ax[0, 0].set_ylabel('Intensity (arb.)')\n",
    "    ax[0, 1].set_title('Ca 8542')\n",
    "    ax[1, 0].set_ylabel('$n_e$ [cm$^{-3}$]')\n",
    "    ax[1, 1].set_ylabel('T [K]')\n",
    "    ax[1,0].set_ylim(0,-20)\n",
    "    ax[1,1].set_ylim(3,8)\n",
    "    ax[2, 0].set_ylabel('v [km/s]')\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('2014-09-06_trans.npz') as transData:\n",
    "    angles = transData['angles']\n",
    "    translations = transData['translations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from matplotlib import patches\n",
    "caFolder = '/mnt/ca/'\n",
    "caFolder = '/local1/scratch/CrispData/2014-09-06/ca8542/'\n",
    "caFiles = sorted([caFolder + f for f in os.listdir(caFolder) if f.endswith('.fits') and not f.startswith('.')])\n",
    "halphaFolder = '/local1/scratch/CrispData/2014-09-06/Halpha/'\n",
    "haFiles = sorted([halphaFolder + f for f in os.listdir(halphaFolder) if f.endswith('.fits') and not f.startswith('.')])\n",
    "\n",
    "haCentralIdx = 7\n",
    "caCentralIdx = 12\n",
    "haHW = 1.4\n",
    "caHW = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "UniformColorMap = False\n",
    "\n",
    "\n",
    "# imageIndices = [0, 10, 100, 500]\n",
    "imageIndices = [400, 460, 482, 500, 510, 520, 540, 561] # indices chosen to have low seeing\n",
    "roiX = range(300,1001)\n",
    "roiY = range(600,1001)\n",
    "\n",
    "# fineRoiX = range(495,506)\n",
    "# fineRoiY = range(825,835)\n",
    "# fineRoiX = range(395,405)\n",
    "# fineRoiY = range(730,740)\n",
    "# fineRoiX = range(663,665)\n",
    "# fineRoiY = range(717,719)\n",
    "fineRoiX = range(865,885)\n",
    "fineRoiY = range(745,765)\n",
    "boxSize = (fineRoiX[-1]-fineRoiX[0], fineRoiY[-1]-fineRoiY[0])\n",
    "\n",
    "haTimes = []\n",
    "caTimes = []\n",
    "haData = []\n",
    "caData = []\n",
    "dataMinHa = 65536\n",
    "dataMinCa = 65536\n",
    "dataMaxHa = 0\n",
    "dataMaxCa = 0\n",
    "\n",
    "with fits.open(haFiles[0]) as hdu:\n",
    "    haWl = hdu[1].data\n",
    "    haCentreWl = hdu[0].header['TWAVE1']\n",
    "    \n",
    "with fits.open(caFiles[0]) as hdu:\n",
    "    caWl = hdu[1].data\n",
    "    caCentreWl = hdu[0].header['TWAVE1']\n",
    "\n",
    "width = int(np.ceil(len(imageIndices)/2))\n",
    "fig, ax = plt.subplots(4, width, figsize=(5 * width // 2,10), sharex=True, sharey=True)\n",
    "ax = np.ravel(ax)\n",
    "for j, i in enumerate(imageIndices):\n",
    "    if j >= width:\n",
    "        j += width\n",
    "\n",
    "    with fits.open(haFiles[i]) as hdu:\n",
    "        ha = hdu[0].data.astype(np.float64)\n",
    "        haTime = hdu[0].header['DATE-AVG']\n",
    "        haTimes.append(haTime)\n",
    "        \n",
    "    with fits.open(caFiles[i]) as hdu:\n",
    "        ca = hdu[0].data.astype(np.float64)\n",
    "        caTime = hdu[0].header['DATE-AVG']\n",
    "        caTimes.append(caTime)\n",
    "        \n",
    "        \n",
    "    haPatch = patches.Rectangle((fineRoiX[0], fineRoiY[0]), boxSize[0], boxSize[1], fill=False, color='r') \n",
    "    caPatch = patches.Rectangle((fineRoiX[0], fineRoiY[0]), boxSize[0], boxSize[1], fill=False, color='r') \n",
    "\n",
    "    trans = AffineTransform(rotation=angles[i], translation=translations[i])\n",
    "    haTrans = [warp(ha[i], trans) for i in range(ha.shape[0])]\n",
    "    haTrans = np.stack(haTrans)\n",
    "    caTrans = [warp(ca[i], trans) for i in range(ca.shape[0])]\n",
    "    caTrans = np.stack(caTrans)\n",
    "    \n",
    "    dataMinHa = min(dataMinHa, haTrans[haCentralIdx][np.ix_(roiX, roiY)].min())\n",
    "    dataMinCa = min(dataMinCa, caTrans[caCentralIdx][np.ix_(roiX, roiY)].min())\n",
    "    \n",
    "    dataMaxHa = max(dataMaxHa, haTrans[haCentralIdx][np.ix_(roiX, roiY)].max())\n",
    "    dataMaxCa = max(dataMaxCa, caTrans[caCentralIdx][np.ix_(roiX, roiY)].max())\n",
    "    \n",
    "    haData.append(haTrans[np.ix_(range(len(haWl)), fineRoiY, fineRoiX)])\n",
    "    caData.append(caTrans[np.ix_(range(len(caWl)), fineRoiY, fineRoiX)])\n",
    "#     ax[j].imshow(ha2[np.ix_(roiX, roiY)])\n",
    "    ax[j].imshow(haTrans[haCentralIdx])\n",
    "    ax[j].set_xlim(roiX[0], roiX[-1])\n",
    "    ax[j].set_ylim(roiY[0], roiY[-1])\n",
    "    ax[j].add_patch(haPatch)\n",
    "    ax[j].set_xlabel(r'H$\\alpha$ ' + haTime[11:])\n",
    "    \n",
    "    ax[j+width].imshow(caTrans[caCentralIdx])\n",
    "    ax[j+width].set_xlim(roiX[0], roiX[-1])\n",
    "    ax[j+width].set_ylim(roiY[0], roiY[-1])\n",
    "    ax[j+width].add_patch(caPatch)\n",
    "    ax[j+width].set_xlabel('Ca 8542 ' + caTime[11:])\n",
    "    \n",
    "if UniformColorMap:\n",
    "    dataMin = min(dataMinHa, dataMinCa)\n",
    "    dataMax = max(dataMaxHa, dataMaxCa)\n",
    "    for j, i in enumerate(imageIndices):\n",
    "        if j >= width:\n",
    "            j += width\n",
    "\n",
    "        [im.set_clim(vmin=dataMin, vmax=dataMax) for im in ax[j].get_images()]\n",
    "        [im.set_clim(vmin=dataMin, vmax=dataMax) for im in ax[j+width].get_images()]\n",
    "\n",
    "    \n",
    "# cbAxis = fig.add_axes([0.1, 0.03, 0.8, 0.03]) \n",
    "# fig.colorbar(ax[0].get_images()[0], orientation='horizontal', cax=cbAxis)\n",
    "fig.tight_layout()\n",
    "fig.canvas.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniformColorMap = True\n",
    "\n",
    "width = int(np.ceil(len(imageIndices)/2))\n",
    "fig, ax = plt.subplots(4, width, figsize=(5 * width // 2,10), sharex=True, sharey=True)\n",
    "ax = np.ravel(ax)\n",
    "gridMax = max([h[haCentralIdx].max() for h in haData] + [c[caCentralIdx].max() for c in caData])\n",
    "gridMin = min([h[haCentralIdx].min() for h in haData] + [c[caCentralIdx].min() for c in caData])\n",
    "\n",
    "if not UniformColorMap:\n",
    "    gridMax = None\n",
    "    gridMin = None\n",
    "\n",
    "for j, i in enumerate(imageIndices):\n",
    "    plotIdx = j + width if j >= width else j\n",
    "        \n",
    "    ax[plotIdx].imshow(haData[j][haCentralIdx], vmin=gridMin, vmax=gridMax)\n",
    "    ax[plotIdx+width].imshow(caData[j][caCentralIdx], vmin=gridMin, vmax=gridMax)\n",
    "    ax[plotIdx].set_xlabel(r'H$\\alpha$: ' + haTimes[j][11:])\n",
    "    ax[plotIdx+width].set_xlabel('Ca 8542: ' + caTimes[j][11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gridIdx, gridX, gridY = 0, 17, 15\n",
    "# gridX2, gridY2 = 9, 1\n",
    "\n",
    "gridIdx, gridX, gridY = 1, 5, 3\n",
    "gridX2, gridY2 = 15, 3\n",
    "\n",
    "# gridIdx, gridX, gridY = 1, 10, 17\n",
    "# gridX2, gridY2 = 6, 5\n",
    "\n",
    "# gridIdx, gridX, gridY = 4, 6, 12\n",
    "# gridX2, gridY2 = 18, 3\n",
    "\n",
    "# gridIdx, gridX, gridY = 2, 1, 11\n",
    "# gridX2, gridY2 = 16, 2\n",
    "\n",
    "# gridIdx, gridX, gridY = 5, 1, 17\n",
    "# gridX2, gridY2 = 11, 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "wlLength = 30\n",
    "haFlat = [np.reshape(h, (h.shape[0],-1)) for h in haData]\n",
    "caFlat = [np.reshape(c, (c.shape[0],-1)) for c in caData]\n",
    "\n",
    "haInput = [np.zeros((wlLength, h.shape[1])) for h in haFlat]\n",
    "caInput = [np.zeros((wlLength, c.shape[1])) for c in caFlat]\n",
    "\n",
    "haInputWl = np.linspace(haCentreWl - haHW, haCentreWl + haHW, num=30) \n",
    "caInputWl = np.linspace(caCentreWl - caHW, caCentreWl + caHW, num=30) \n",
    "\n",
    "for i in range(len(haFlat)):\n",
    "    for j in range(haFlat[i].shape[1]):\n",
    "        haInterp = interp1d(haWl, haFlat[i][:,j], kind='linear')\n",
    "        caInterp = interp1d(caWl, caFlat[i][:,j], kind='linear')\n",
    "        \n",
    "        haInput[i][:,j] = haInterp(haInputWl)\n",
    "        caInput[i][:,j] = caInterp(caInputWl)\n",
    "\n",
    "\n",
    "peakEmission = [np.zeros(h.shape[1]) for h in haFlat]\n",
    "for i in range(len(haFlat)):\n",
    "    for j in range(haFlat[i].shape[1]):\n",
    "        peakEmission[i][j] = max(np.amax(haInput[i][:,j]), np.amax(caInput[i][:,j]))\n",
    "        haInput[i][:,j] /= peakEmission[i][j]\n",
    "        caInput[i][:,j] /= peakEmission[i][j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haGrid = [h.reshape((wlLength, haData[0].shape[1], -1)) for h in haInput]\n",
    "caGrid = [c.reshape((wlLength, caData[0].shape[1], -1)) for c in caInput]\n",
    "\n",
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].plot(haInputWl, haGrid[gridIdx][:, gridY, gridX])\n",
    "# ax[0,0].plot(haWl, haData[gridIdx][:, gridY, gridX] / haData[gridIdx][:, gridY, gridX].max())\n",
    "ax[0,1].plot(caInputWl, caGrid[gridIdx][:, gridY, gridX])\n",
    "# ax[0,1].plot(caWl, caData[gridIdx][:, gridY, gridX] / caData[gridIdx][:, gridY, gridX].max())\n",
    "ax[1,0].plot(haInputWl, haGrid[gridIdx][:, gridY2, gridX2])\n",
    "# ax[1,0].plot(haWl, haData[gridIdx][:, gridY2, gridX2] / haData[gridIdx][:, gridY2, gridX2].max())\n",
    "ax[1,1].plot(caInputWl, caGrid[gridIdx][:, gridY2, gridX2])\n",
    "# ax[1,1].plot(caWl, caData[gridIdx][:, gridY2, gridX2] / caData[gridIdx][:, gridY2, gridX2].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batchSize = 100\n",
    "    a = max(1.0 / batchSize, 0.002)\n",
    "    y = torch.ones((batchSize, 2, wlLength))\n",
    "    y[:, 0] *= torch.from_numpy(haGrid[gridIdx][:, gridY, gridX]).float()\n",
    "    y[:, 1] *= torch.from_numpy(caGrid[gridIdx][:, gridY, gridX]).float()\n",
    "    yz = model.outSchema.fill({'Halpha': y[:, 0] + 0.0 * torch.randn(y[:,0].shape), 'Ca8542': y[:, 1] + 0.0 * torch.randn(y[:,1].shape), 'LatentSpace': torch.randn})\n",
    "    xOut = model(yz.to(dev), rev=True)\n",
    "    yRoundTrip = model(xOut)\n",
    "    \n",
    "    vSign = xOut[:, model.inSchema.vel] / torch.abs(xOut[:, model.inSchema.vel])\n",
    "    vSign[torch.isnan(vSign)] = 0\n",
    "    vel = vSign * (10**torch.abs(xOut[:, model.inSchema.vel]) - 1.0)\n",
    "    fig, ax = plt.subplots(3,2)\n",
    "    for i in range(batchSize):\n",
    "        ax[1, 0].plot(data.z.numpy(), xOut[i, model.inSchema.ne].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[1, 1].plot(data.z.numpy(), xOut[i, model.inSchema.temperature].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[2, 0].plot(data.z.numpy(), vel[i].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[0, 0].plot(haInputWl, yRoundTrip[i, model.outSchema.Halpha].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[0, 1].plot(caInputWl, yRoundTrip[i, model.outSchema.Ca8542].cpu().numpy(), c='r', alpha=a)\n",
    "        \n",
    "    ax[0, 0].plot(haInputWl, yz[0, model.outSchema.Halpha].cpu().numpy(), '--')\n",
    "    ax[0, 0].set_title(r'H$\\alpha$')\n",
    "    ax[0, 0].set_ylabel('Intensity (arb.)')\n",
    "    ax[0, 1].plot(caInputWl, yz[0, model.outSchema.Ca8542].cpu().numpy(), '--')\n",
    "    ax[0, 1].set_title('Ca 8542')\n",
    "#     ax[1, 0].set_ylim(8, 17)\n",
    "    ax[1, 0].set_ylim(0, -20)\n",
    "    ax[1, 0].set_ylabel('$n_e$ [cm$^{-3}$]')\n",
    "    ax[1, 1].set_ylim(3, 8)\n",
    "    ax[1, 1].set_ylabel('T [K]')\n",
    "    ax[2, 0].set_ylabel('v [km/s]')\n",
    "    ax[1,0].get_shared_x_axes().join(ax[1,0],ax[1,1],ax[2,0])\n",
    "\n",
    "    ax[2,1].imshow(haData[gridIdx][haCentralIdx])\n",
    "    ax[2,1].plot(gridX, gridY, 'ro')\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batchSize = 100\n",
    "    a = max(1.0 / batchSize, 0.002)\n",
    "    y = torch.ones((batchSize, 2, wlLength))\n",
    "    y[:, 0] *= torch.from_numpy(haGrid[gridIdx][:, gridY2, gridX2]).float()\n",
    "    y[:, 1] *= torch.from_numpy(caGrid[gridIdx][:, gridY2, gridX2]).float()\n",
    "    yz = model.outSchema.fill({'Halpha': y[:, 0] + 0.0 * torch.randn(y[:,0].shape), 'Ca8542': y[:, 1] + 0.0 * torch.randn(y[:,1].shape), 'LatentSpace': torch.randn})\n",
    "    xOut = model(yz.to(dev), rev=True)\n",
    "    yRoundTrip = model(xOut)\n",
    "    \n",
    "    vSign = xOut[:, model.inSchema.vel] / torch.abs(xOut[:, model.inSchema.vel])\n",
    "    vSign[torch.isnan(vSign)] = 0\n",
    "    vel = vSign * (10**torch.abs(xOut[:, model.inSchema.vel]) - 1.0)\n",
    "    fig, ax = plt.subplots(3,2)\n",
    "    for i in range(batchSize):\n",
    "        ax[1, 0].plot(data.z.numpy(), xOut[i, model.inSchema.ne].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[1, 1].plot(data.z.numpy(), xOut[i, model.inSchema.temperature].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[2, 0].plot(data.z.numpy(), vel[i].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[0, 0].plot(haInputWl, yRoundTrip[i, model.outSchema.Halpha].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[0, 1].plot(caInputWl, yRoundTrip[i, model.outSchema.Ca8542].cpu().numpy(), c='r', alpha=a)\n",
    "        \n",
    "    ax[0, 0].plot(haInputWl, yz[0, model.outSchema.Halpha].cpu().numpy(), '--')\n",
    "    ax[0, 0].set_title(r'H$\\alpha$')\n",
    "    ax[0, 0].set_ylabel('Intensity (arb.)')\n",
    "    ax[0, 1].plot(caInputWl, yz[0, model.outSchema.Ca8542].cpu().numpy(), '--')\n",
    "    ax[0, 1].set_title('Ca 8542')\n",
    "#     ax[1, 0].set_ylim(8, 17)\n",
    "    ax[1, 0].set_ylim(0, -20)\n",
    "    ax[1, 0].set_ylabel('$n_e$ [cm$^{-3}$]')\n",
    "    ax[1, 1].set_ylim(3, 8)\n",
    "    ax[1, 1].set_ylabel('T [K]')\n",
    "    ax[2, 0].set_ylabel('v [km/s]')\n",
    "    ax[1,0].get_shared_x_axes().join(ax[1,0],ax[1,1],ax[2,0])\n",
    "\n",
    "    ax[2,1].imshow(haData[gridIdx][haCentralIdx])\n",
    "    ax[2,1].plot(gridX2, gridY2, 'ro')\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
