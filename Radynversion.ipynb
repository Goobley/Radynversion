{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from Inn2 import RadynversionNet, AtmosData, RadynversionTrainer\n",
    "import loss as Loss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "from time import time\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLocation1 = '/local0/scratch/HAlphaGridExportStatic/DoublePicoMegaMassPickle50.pickle'\n",
    "# dataLocation3 = '/local0/scratch/HAlphaGridExportStatic/MiniBalancedTraining.pickle'\n",
    "# dataLocation2 = '/local0/scratch/HAlphaGridExportStatic/TestPickle50.pickle'\n",
    "# dataLocation = '/local0/scratch/Chris/DoublePicoMegaPickle50.pickle'\n",
    "# dataLocation = 'G:\\\\DoublePicoMegaPickle.pickle'\n",
    "balancedData = 'MiniBalancedTraining.pickle'\n",
    "\n",
    "data = AtmosData([dataLocation1], resampleWl=30)\n",
    "# data = AtmosData([balancedData], resampleWl=30)\n",
    "data.split_data_and_init_loaders(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Inv0 has following input dimensions:\n",
      "\t Output #0 of node Input (0-pad extra channels): (384,)\n",
      "\n",
      "Node Permute0 has following input dimensions:\n",
      "\t Output #0 of node Inv0: (384,)\n",
      "\n",
      "Node Inv1 has following input dimensions:\n",
      "\t Output #0 of node Permute0: (384,)\n",
      "\n",
      "Node Permute1 has following input dimensions:\n",
      "\t Output #0 of node Inv1: (384,)\n",
      "\n",
      "Node Inv2 has following input dimensions:\n",
      "\t Output #0 of node Permute1: (384,)\n",
      "\n",
      "Node Permute2 has following input dimensions:\n",
      "\t Output #0 of node Inv2: (384,)\n",
      "\n",
      "Node Inv3 has following input dimensions:\n",
      "\t Output #0 of node Permute2: (384,)\n",
      "\n",
      "Node Permute3 has following input dimensions:\n",
      "\t Output #0 of node Inv3: (384,)\n",
      "\n",
      "Node Inv4 has following input dimensions:\n",
      "\t Output #0 of node Permute3: (384,)\n",
      "\n",
      "Node Output has following input dimensions:\n",
      "\t Output #0 of node Inv4: (384,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inRepr = [('ne', data.ne.shape[1]), ('temperature', data.temperature.shape[1]), ('vel', data.vel.shape[1]), ('!!PAD',)]\n",
    "outRepr = [('LatentSpace', int(data.ne.shape[1]*3)), ('!!PAD',), ('Halpha', data.lines[0].shape[1]), ('Ca8542', data.lines[1].shape[1])]\n",
    "model = RadynversionNet(inRepr, outRepr, dropout=0.00, zeroPadding=0, minSize=384, numInvLayers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('LatentSpace', 150), ('!!ZeroPadding', 174), ('Halpha', 30), ('Ca8542', 30)],\n",
       " [('ne', 50), ('temperature', 50), ('vel', 50), ('!!ZeroPadding', 234)],\n",
       " 384,\n",
       " 384,\n",
       " RadynversionNet(\n",
       "   (module_list): ModuleList(\n",
       "     (0): None\n",
       "     (1): rev_multiplicative_layer(\n",
       "       (s1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (s2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "     )\n",
       "     (2): permute_layer()\n",
       "     (3): rev_multiplicative_layer(\n",
       "       (s1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (s2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "     )\n",
       "     (4): permute_layer()\n",
       "     (5): rev_multiplicative_layer(\n",
       "       (s1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (s2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "     )\n",
       "     (6): permute_layer()\n",
       "     (7): rev_multiplicative_layer(\n",
       "       (s1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (s2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "     )\n",
       "     (8): permute_layer()\n",
       "     (9): rev_multiplicative_layer(\n",
       "       (s1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t1): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (s2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "       (t2): F_fully_connected_leaky(\n",
       "         (d1): Dropout(p=0.0)\n",
       "         (d2): Dropout(p=0.0)\n",
       "         (d2b): Dropout(p=0.0)\n",
       "         (fc1): Linear(in_features=192, out_features=384, bias=True)\n",
       "         (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2b): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc2d): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (fc3): Linear(in_features=384, out_features=192, bias=True)\n",
       "         (nl1): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2b): LeakyReLU(negative_slope=0.01)\n",
       "         (nl2d): ReLU()\n",
       "       )\n",
       "     )\n",
       "     (10): dummy()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outSchema, model.inSchema, len(model.outSchema), len(model.inSchema), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "x, y = next(iter(data.trainLoader))\n",
    "ax[0].plot(x[0, 0, :].numpy())\n",
    "ax[1].plot(x[0, 1, :].numpy())\n",
    "ax[1].plot(x[0, 2, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RadynversionTrainer(model, data, dev)\n",
    "trainer.training_params(1200, lr=1.5e-3, zerosNoiseScale=5e-2, wPred=4000.0, wLatent=900.0, wRev=1000.0,\n",
    "#                         loss_latent=Loss.mmd_multiscale_on(dev, alphas=[3, 4, 6, 9, 16]),\n",
    "                        loss_latent=Loss.mmd_multiscale_on(dev, alphas=[8, 11]),\n",
    "#                         loss_backward=Loss.mmd_multiscale_on(dev, alphas=[4, 5, 6, 12, 30]),\n",
    "                        loss_backward=Loss.mmd_multiscale_on(dev, alphas=[1.4, 2, 5.5, 7]),\n",
    "                        loss_fit=Loss.mse)\n",
    "totalEpochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "fMse = []\n",
    "bMse = []\n",
    "lossVec = [[] for _ in range(4)]\n",
    "lossLabels = ['L2 Line', 'MMD Latent', 'MMD Reverse', 'L2 Reverse']\n",
    "out = None\n",
    "fig, axis = plt.subplots(4,1, figsize=(10,8))\n",
    "# axis2 = axis[1].twinx()\n",
    "# axis1a = axis[0].twinx()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "alphaRange, mmdF, mmdB, idxF, idxB = [1], [1], [1], 0, 0\n",
    "try:\n",
    "    tStart = time()\n",
    "    for epoch in range(trainer.numEpochs):\n",
    "        totalEpochs += 1\n",
    "\n",
    "        trainer.scheduler.step()\n",
    "        \n",
    "        loss, indLosses = trainer.train(epoch)\n",
    "        \n",
    "        axis[0].clear()\n",
    "#         axis1a.clear()\n",
    "        axis[1].clear()\n",
    "#         axis2.clear()\n",
    "        axis[2].clear()\n",
    "        axis[3].clear()\n",
    "        if epoch > 5:\n",
    "            for i in range(len(indLosses)):\n",
    "                lossVec[i].append(indLosses[i])\n",
    "            losses.append(loss)\n",
    "            fig.suptitle('Current Loss: %.2e, min loss: %.2e' % (loss, np.min(np.abs(losses))))\n",
    "            axis[0].semilogy(np.arange(len(losses)), np.abs(losses))\n",
    "            for i, lo in enumerate(lossVec):\n",
    "                axis[1].semilogy(np.arange(len(losses)), lo, '--', label=lossLabels[i])\n",
    "            axis[1].legend(loc='upper left')\n",
    "            tNow = time()\n",
    "            elapsed = int(tNow - tStart)\n",
    "            eta = int((tNow - tStart) / (epoch + 1) * trainer.numEpochs) - elapsed\n",
    "\n",
    "            if epoch % 2 == 0:\n",
    "                mses = trainer.test()\n",
    "                fMse.append(mses[0])\n",
    "                bMse.append(mses[1])\n",
    "                out = mses[2]\n",
    "                \n",
    "            if epoch % 5 == 0:\n",
    "                alphaRange, mmdF, mmdB, idxF, idxB = trainer.review_mmd()\n",
    "                \n",
    "            axis[3].semilogx(alphaRange, mmdF, label='Latent Space')\n",
    "            axis[3].semilogx(alphaRange, mmdB, label='Backward')\n",
    "            axis[3].semilogx(alphaRange[idxF], mmdF[idxF], 'ro')\n",
    "            axis[3].semilogx(alphaRange[idxB], mmdB[idxB], 'ro')\n",
    "            axis[3].legend()\n",
    "\n",
    "#             axis[1].semilogy(np.arange(len(fMse)), np.abs(fMse), 'r')\n",
    "#             axis2.semilogy(np.arange(len(bMse)), np.abs(bMse), 'g')\n",
    "            testTime = time() - tNow\n",
    "            axis[2].plot(out[0, model.outSchema.Halpha].cpu().numpy())\n",
    "            axis[2].plot(out[0, model.outSchema.Ca8542].cpu().numpy())\n",
    "            for a in axis:\n",
    "                a.grid()\n",
    "            axis[3].set_xlabel('Epochs: %d, Elapsed: %d s, ETA: %d s (Testing: %d s)' % (epoch, elapsed, eta, testTime))\n",
    "            \n",
    "            \n",
    "        fig.canvas.draw()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print(f\"\\n\\nTraining took {(time()-tStart)/60:.2f} minutes\\n\")\n",
    "#     totalEpochs += len(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.canvas.draw()\n",
    "# idxFor\n",
    "trainer.numEpochs = 200\n",
    "# trainer.zerosNoiseScale = 0.0\n",
    "trainer.wPred = 9000\n",
    "# trainer.wLatent = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint('checkpt_mass_800.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/4\n",
    "# model.to('cpu')\n",
    "save_checkpoint({\n",
    "    'epoch': totalEpochs,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': trainer.optim.state_dict(),\n",
    "    'scheduler': trainer.scheduler.state_dict(),\n",
    "}, filename='checkpt_mass_800.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_checkpoint(filename):\n",
    "        if os.path.isfile(filename):\n",
    "            print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "            checkpoint = torch.load(filename)\n",
    "            totalEpochs = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            trainer.optim.load_state_dict(checkpoint['optimizer'])\n",
    "            trainer.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(data.testLoader))\n",
    "#     xPad = torch.cat((x, torch.zeros(trainer.miniBatchSize, model.totChannels - model.numXChannels, model.channelSize + model.zeroPadding)), dim=1)\n",
    "#     xPadShape = xPad.shape\n",
    "#     xPad = torch.reshape(xPad, (trainer.miniBatchSize, -1))\n",
    "    x = x.to(dev)\n",
    "    pad_fn = lambda *x: torch.zeros(*x, device=dev)\n",
    "    inp = model.inSchema.fill({'ne': x[:, 0],\n",
    "                                'temperature': x[:, 1],\n",
    "                                'vel': x[:, 2]},\n",
    "                               zero_pad_fn=pad_fn)\n",
    "    yz = model(inp.to(dev))\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].plot(yz[0, model.outSchema.Halpha].cpu().numpy())\n",
    "    ax[0].plot(y[0, 0].numpy())\n",
    "    ax[1].plot(yz[0, model.outSchema.Ca8542].cpu().numpy())\n",
    "    ax[1].plot(y[0, 1].numpy()); fig.show(); fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(data.testLoader))\n",
    "    a = max(1.0 / x.shape[0], 0.002)\n",
    "    y = torch.ones_like(y) * y[0, :, :]\n",
    "    yz = model.outSchema.fill({'Halpha': y[:, 0], 'Ca8542': y[:, 1], 'LatentSpace': torch.randn})\n",
    "    xOut = model(yz.to(dev), rev=True)\n",
    "    fig, ax = plt.subplots(3,2)\n",
    "    ax[0, 0].plot(yz[0, model.outSchema.Halpha].cpu().numpy())\n",
    "    ax[0, 1].plot(yz[0, model.outSchema.Ca8542].cpu().numpy())\n",
    "    for i in range(x.shape[0]):\n",
    "        ax[1, 0].plot(xOut[i, model.inSchema.ne].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[1, 1].plot(xOut[i, model.inSchema.temperature].cpu().numpy(), c='r', alpha=a)\n",
    "        ax[2, 0].plot(xOut[i, model.inSchema.vel].cpu().numpy(), c='r', alpha=a)\n",
    "    ax[1, 0].plot(x[0, 0].cpu().numpy(), '--')\n",
    "    ax[1, 1].plot(x[0, 1].cpu().numpy(), '--')\n",
    "    ax[2, 0].plot(x[0, 2].cpu().numpy(), '--')\n",
    "#     ax[1, 0].set_ylim(8, 17)\n",
    "    ax[1, 0].set_ylim(0, -20)\n",
    "    ax[1, 1].set_ylim(3, 7)\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Investigate retain_graph!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data.testLoader))\n",
    "torch.isnan(x[:, 2]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[-1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmd = Loss.mmd_multiscale_on('cpu')\n",
    "def mmd_multiscale_on(dev):\n",
    "    def mmd_multiscale(x, y):\n",
    "        xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "        rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "        ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "        dxx = rx.t() + rx - 2.*xx\n",
    "        dyy = ry.t() + ry - 2.*yy\n",
    "        dxy = rx.t() + ry - 2.*zz\n",
    "\n",
    "        XX, YY, XY = (torch.zeros(xx.shape).to(dev),\n",
    "\n",
    "                      torch.zeros(xx.shape).to(dev),\n",
    "                      torch.zeros(xx.shape).to(dev))\n",
    "\n",
    "        for a in [0.2, 0.5, 0.9, 1.3, 2.4, 5.0, 10.0, 20.0, 40.0]:\n",
    "#         for a in [0.05, 0.125, 0.225, 0.325]:\n",
    "            XX += a**2 * (a**2 + dxx)**-1\n",
    "            YY += a**2 * (a**2 + dyy)**-1\n",
    "            XY += a**2 * (a**2 + dxy)**-1\n",
    "\n",
    "        return torch.mean(XX + YY - 2.*XY)\n",
    "    return mmd_multiscale\n",
    "def mmd_singlescale_on(a, dev):\n",
    "    def mmd_singlescale(x, y):\n",
    "        xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "        rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "        ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "        dxx = rx.t() + rx - 2.*xx\n",
    "        dyy = ry.t() + ry - 2.*yy\n",
    "        dxy = rx.t() + ry - 2.*zz\n",
    "\n",
    "        XX, YY, XY = (torch.zeros(xx.shape).to(dev),\n",
    "\n",
    "                      torch.zeros(xx.shape).to(dev),\n",
    "                      torch.zeros(xx.shape).to(dev))\n",
    "\n",
    "#         for a in [0.2, 0.5, 0.9, 1.3, 2.4, 5.0, 10.0, 20.0, 40.0]:\n",
    "#         for a in [0.05, 0.125, 0.225, 0.325]:\n",
    "        XX += a**2 * (a**2 + dxx)**-1\n",
    "        YY += a**2 * (a**2 + dyy)**-1\n",
    "        XY += a**2 * (a**2 + dxy)**-1\n",
    "\n",
    "        return torch.mean(XX + YY - 2.*XY)\n",
    "    return mmd_singlescale\n",
    "\n",
    "mmd = mmd_singlescale_on(256, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd(torch.randn(300, 256), torch.ones(300, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "dim = 100\n",
    "loadIter = iter(data.testLoader)\n",
    "x1, y1 = next(loadIter)\n",
    "x2, y2 = next(loadIter)\n",
    "# mmd(torch.randn(batch, dim), torch.randn(batch, dim))\n",
    "mmd(x1.reshape(x1.shape[0], -1), x2.reshape(x2.shape[0], -1))\n",
    "# mmd(x1.reshape(x1.shape[0], -1), torch.ones(x1.reshape(x1.shape[0], -1).shape))\n",
    "\n",
    "# x1 = x1[:batch]\n",
    "# x2 = x2[:batch]\n",
    "xp = model.inSchema.fill({'ne': x1[:, 0] + 0*torch.ones(x1[:, 0].shape), \n",
    "                               'temperature': x1[:, 1] + 0*torch.ones(x1[:, 0].shape), \n",
    "                               'vel': x1[:, 2] + 0*torch.ones(x1[:, 0].shape)},\n",
    "                              zero_pad_fn=torch.zeros)\n",
    "xp2 = model.inSchema.fill({'ne': x2[:, 0] + 0*torch.ones(x2[:, 0].shape) + 1e-3 * torch.randn(x2[:, 1].shape), \n",
    "                               'temperature': x2[:, 1] + 0*torch.ones(x2[:, 0].shape) + 0.0 * torch.randn(x2[:, 0].shape), \n",
    "                               'vel': x2[:, 2] + 0*torch.ones(x2[:, 0].shape) + 0.0 * torch.ones(x2[:, 0].shape)},\n",
    "                              zero_pad_fn=lambda *x: 0. * torch.randn(*x))\n",
    "xp2s = []\n",
    "for i in range(10):\n",
    "    xp2s.append(model.inSchema.fill({'ne': x2[:, 0] + 0.1 *torch.ones(x2[:, 0].shape) + 0.1 * i * torch.randn(x2[:, 1].shape), \n",
    "                               'temperature': x2[:, 1] + 0*torch.ones(x2[:, 0].shape) + 0.0 * torch.randn(x2[:, 0].shape), \n",
    "                               'vel': x2[:, 2] + 0*torch.ones(x2[:, 0].shape) + 0.0 * torch.ones(x2[:, 0].shape)},\n",
    "                              zero_pad_fn=lambda *x: 0.0 * i * torch.ones(*x)))\n",
    "# mmd(xp, xp2).item() * 1e8\n",
    "\n",
    "mmdVals = []\n",
    "r = np.linspace(1.0, 500, num=500)\n",
    "for xp2 in xp2s:\n",
    "    mmdVals.append([])\n",
    "    for a in r:\n",
    "        mm = mmd_singlescale_on(a, 'cpu')\n",
    "        mmdVals[-1].append(mm(xp, xp2).item())\n",
    "\n",
    "plt.figure()\n",
    "for x in mmdVals:\n",
    "    plt.semilogx(r, x)\n",
    "\n",
    "# 30 for channel swapping\n",
    "# 12 for channel offset\n",
    "# 4-6 for 0-pad noise\n",
    "# 4-5 for channel noise\n",
    "# 6-10 for 0-pad dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "dim = 100\n",
    "loadIter = iter(data.testLoader)\n",
    "x1, y1 = next(loadIter)\n",
    "x2, y2 = next(loadIter)\n",
    "# mmd(torch.randn(batch, dim), torch.randn(batch, dim))\n",
    "mmd(x1.reshape(x1.shape[0], -1), x2.reshape(x2.shape[0], -1))\n",
    "# mmd(x1.reshape(x1.shape[0], -1), torch.ones(x1.reshape(x1.shape[0], -1).shape))\n",
    "\n",
    "# x1 = x1[:batch]\n",
    "# x2 = x2[:batch]\n",
    "yp = model.outSchema.fill({'Halpha': y1[:, 0] + 0*torch.ones(y1[:, 0].shape), \n",
    "                               'Ca8542': y1[:, 1] + 0*torch.ones(y1[:, 0].shape), \n",
    "                               'LatentSpace': torch.randn},\n",
    "                              zero_pad_fn=torch.zeros)\n",
    "yp2 = model.outSchema.fill({'Halpha': y2[:, 0] + 0*torch.ones(y1[:, 0].shape) + 1e-3 * torch.randn(y1[:, 1].shape), \n",
    "                               'Ca8542': y2[:, 1] + 0*torch.ones(y1[:, 0].shape) + 0.0 * torch.randn(y1[:, 0].shape), \n",
    "                               'LatentSpace': torch.randn},\n",
    "                              zero_pad_fn=lambda *x: 0. * torch.randn(*x))\n",
    "yp2s = []\n",
    "for i in range(10):\n",
    "    yp2s.append(model.outSchema.fill({'Halpha': y2[:, 0] + 0*torch.ones(y2[:, 0].shape) + 1e-1 * torch.randn(y2[:, 1].shape), \n",
    "                               'Ca8542': y2[:, 1] + 0*torch.ones(y2[:, 0].shape) + 1e-1 * torch.randn(y2[:, 0].shape), \n",
    "                               'LatentSpace': lambda *x: 0.95 * torch.randn(*x) + 0.0 * torch.ones(*x)},\n",
    "                              zero_pad_fn=lambda *x: 0.1 * i * torch.randn(*x)))\n",
    "# mmd(xp, xp2).item() * 1e8\n",
    "\n",
    "mmdVals = []\n",
    "r = np.linspace(1.0, 500, num=500)\n",
    "for yp2 in yp2s:\n",
    "    mmdVals.append([])\n",
    "    for a in r:\n",
    "        mm = mmd_singlescale_on(a, 'cpu')\n",
    "        mmdVals[-1].append(mm(yp, yp2).item())\n",
    "\n",
    "plt.figure()\n",
    "for x in mmdVals:\n",
    "    plt.semilogx(r, x)\n",
    "\n",
    "# 8-9.5-12 for channel swapping\n",
    "# 12-18 for channel offset\n",
    "# 4-7 for latent space dist\n",
    "# 14 for latent space offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loadIter = iter(data.testLoader)\n",
    "    x1, y1 = next(loadIter)\n",
    "    xp = model.inSchema.fill({'ne': x1[:, 0],\n",
    "                                   'temperature': x1[:, 1],\n",
    "                                   'vel': x1[:, 2]},\n",
    "                                  zero_pad_fn=torch.zeros).to(dev)\n",
    "    yp = model.outSchema.fill({'Halpha': y1[:, 0], \n",
    "                                   'Ca8542': y1[:, 1], \n",
    "                                   'LatentSpace': torch.randn},\n",
    "                                  zero_pad_fn=torch.zeros).to(dev)\n",
    "    yFor = model(xp.to(dev))\n",
    "    mse = Loss.mse(yp, yFor)\n",
    "    yForNp = torch.cat((yFor[:, model.outSchema.Halpha], yFor[:, model.outSchema.Ca8542], yFor[:, model.outSchema.LatentSpace]), dim=1).to(dev)\n",
    "    ynp = torch.cat((yp[:, model.outSchema.Halpha], yp[:, model.outSchema.Ca8542], yp[:, model.outSchema.LatentSpace]), dim=1).to(dev)\n",
    "\n",
    "\n",
    "    r = np.logspace(-3, np.log10(500), num=2000)\n",
    "    mmdVals = []\n",
    "    for a in r:\n",
    "        mm = mmd_singlescale_on(float(a), dev)\n",
    "        mmdVals.append(mm(yForNp, ynp).item())\n",
    "        \n",
    "    mmdVals = np.array(mmdVals)\n",
    "    def find_turning_rev(a):\n",
    "        aRev = a[::-1]\n",
    "        for i, v in enumerate(a[-2::-1]):\n",
    "            if v < aRev[i]:\n",
    "                return len(a)-i\n",
    "            \n",
    "            \n",
    "    tp = find_turning_rev(mmdVals)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.semilogx(r, mmdVals)\n",
    "    plt.semilogx(r[tp], mmdVals[tp], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loadIter = iter(data.testLoader)\n",
    "    x1, y1 = next(loadIter)\n",
    "    xp = model.inSchema.fill({'ne': x1[:, 0],\n",
    "                                   'temperature': x1[:, 1],\n",
    "                                   'vel': x1[:, 2]},\n",
    "                                  zero_pad_fn=torch.zeros).to(dev)\n",
    "    yp = model.outSchema.fill({'Halpha': y1[:, 0], \n",
    "                                   'Ca8542': y1[:, 1], \n",
    "                                   'LatentSpace': torch.randn},\n",
    "                                  zero_pad_fn=torch.zeros).to(dev)\n",
    "    xBack = model(yp, rev=True)\n",
    "    mse = Loss.mse(xp, xBack)\n",
    "#     xBackNp = torch.cat((xBack[:, model.inSchema.ne], xBack[:, model.outSchema.temperature], xBack[:, model.outSchema.vel], yFor[:, model.outSchema.LatentSpace]), dim=1).to(dev)\n",
    "#     ynp = torch.cat((yp[:, model.outSchema.Halpha], yp[:, model.outSchema.Ca8542], yp[:, model.outSchema.LatentSpace]), dim=1).to(dev)\n",
    "\n",
    "\n",
    "    r = np.logspace(-3, np.log10(500), num=5000)\n",
    "    mmdVals = []\n",
    "    for a in r:\n",
    "        mm = mmd_singlescale_on(float(a), dev)\n",
    "        mmdVals.append(mm(xp[:, model.inSchema.ne[0]:model.inSchema.vel[-1]+1], xBack[:, model.inSchema.ne[0]:model.inSchema.vel[-1]+1]).item())\n",
    "        \n",
    "    mmdVals = np.array(mmdVals)\n",
    "    tp = find_turning_rev(mmdVals)\n",
    "    \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.semilogx(r, mmdVals)\n",
    "    plt.semilogx(r[tp], mmdVals[tp], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loss_latent(yForNp, ynp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(yFor[20, model.outSchema.LatentSpace].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
